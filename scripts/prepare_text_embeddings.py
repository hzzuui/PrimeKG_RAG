# å»ºæ§‹ NLP å‘é‡è³‡æ–™åº«ï¼Œåƒ…åœ¨è³‡æ–™æ›´æ–°æ™‚åŸ·è¡Œ 
# å»ºç«‹ collection_text (å–® hop)
# prepare_text_embeddings.py
import sys
import os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from backend.neo4j_connect import Neo4jConnection
from backend.milvus_connection import connect_milvus, create_collection
from sentence_transformers import SentenceTransformer
import json

# === Step 1: å¾ Neo4j æŸ¥è©¢ç¯€é»(disease,gene,drug) ===
def extract_nodes():
    conn = Neo4jConnection()
    query = """
        MATCH path=(n)-[r:bioprocess_protein|pathway_protein|disease_protein|drug_effect|indication|phenotype_protein|drug_protein]-(m)
        RETURN n, r, m
    """
    data = conn.query(query)

    # === ä¿å­˜åŸå§‹ Neo4j Path çµæœ ===
    raw_results = []
    for record in data:
        raw_results.append({
            "n": dict(record["n"]),   # ä¿ç•™å®Œæ•´ node n
            "r": record["r"].type,    # é—œä¿‚å‹åˆ¥
            "m": dict(record["m"])    # ä¿ç•™å®Œæ•´ node m
        })

    with open("neo4j_path.json", "w", encoding="utf-8") as f:
        json.dump(raw_results, f, ensure_ascii=False, indent=4)

    # === ä¿å­˜ç²¾ç°¡å¾Œçš„ä¸‰å…ƒçµ„ ===
    triples = []
    for record in data:
        n = record["n"]
        r = record["r"]
        m = record["m"]

        triples.append({
            "source_name": n["node_name"],
            "relation_type": r.type,
            "target_name": m["node_name"]
        })

    with open("neo4j_triples.json", "w", encoding="utf-8") as f:
        json.dump(triples, f, ensure_ascii=False, indent=4)

    conn.close()
    print(f"âœ… Saved {len(raw_results)} raw paths to neo4j_path.json")
    print(f"âœ… Saved {len(triples)} triples to neo4j_triples.json")


# === Step 2: å°‡ä¸‰å…ƒçµ„è½‰å‘é‡ä¸¦å¯«å…¥ Milvus ===
def insert_text_embeddings(data, model, collection):
    vector_data = []
    seen = set()

    for item in data:
        source_name = item["source_name"]
        relation_type = item["relation_type"]
        target_name = item["target_name"]

        key = (source_name, relation_type, target_name)
        if key in seen:
            continue
        seen.add(key)

        # ğŸŸ¢ Step 1: å»ºç«‹è‡ªç„¶èªè¨€åŒ–å¥å­
        if relation_type == "drug_protein":
            text = f"The drug {source_name} targets the gene {target_name}."
        elif relation_type == "indication":
            text = f"The drug {source_name} is used to treat the disease {target_name}."
        elif relation_type == "disease_protein":
            text = f"The disease {source_name} is associated with the gene {target_name}."
        else:
            text = f"{source_name} {relation_type} {target_name}."

        # ğŸŸ¢ Step 2: è½‰å‘é‡
        embedding = model.encode(text).tolist()

        # ğŸŸ¢ Step 3: å­˜é€² collection
        row = {
            "source_name": source_name,
            "relation_type": relation_type,
            "target_name": target_name,
            "triple_text": text,
            "embedding": embedding
        }
        vector_data.append(row)

    # æ’å…¥ Milvus
    if vector_data:
        collection.insert(vector_data)
        collection.flush()
        print(f"âœ… Inserted {len(vector_data)} text embeddings into Milvus.")
        print("ç•¶å‰ entities æ•¸:", collection.num_entities)
    else:
        print("âš ï¸ æ²’æœ‰è¦æ’å…¥çš„è³‡æ–™ï¼")

# === Main åŸ·è¡Œå€ ===
if __name__ == "__main__":
    print("step 1 : é€£ç·šè‡³ Neo4j ä¸¦æ“·å–è³‡æ–™...")
    extract_nodes()

    print("step 2 : é€£ç·š Milvus ä¸¦å»ºç«‹ collection_text")
    connect_milvus()
    collection_text = create_collection(name="collection_text", dim=768)
    collection_text.load()

    print("step 3 : å‘é‡åŒ–æ–‡å­—ä¸¦å¯«å…¥ Milvus")
    with open("neo4j_triples.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    model = SentenceTransformer("all-mpnet-base-v2")

    # æ‰¹æ¬¡è™•ç† + progress bar
    texts = []
    for item in data:
        if item["relation_type"] == "drug_protein":
            text = f"The drug {item['source_name']} targets the gene {item['target_name']}."
        elif item["relation_type"] == "indication":
            text = f"The drug {item['source_name']} is used to treat the disease {item['target_name']}."
        elif item["relation_type"] == "disease_protein":
            text = f"The disease {item['source_name']} is associated with the gene {item['target_name']}."
        else:
            text = f"{item['source_name']} {item['relation_type']} {item['target_name']}."
        texts.append((item["source_name"], item["relation_type"], item["target_name"], text))

    print(f"å…± {len(texts)} ç­†ï¼Œé–‹å§‹å‘é‡åŒ–...")
    embeddings = model.encode([t[3] for t in texts], batch_size=64, show_progress_bar=True).tolist()

    vector_data = []
    for (source_name, relation_type, target_name, text), emb in zip(texts, embeddings):
        vector_data.append({
            "source_name": source_name,
            "relation_type": relation_type,
            "target_name": target_name,
            "triple_text": text,
            "embedding": emb
        })

    # åˆ†æ‰¹æ’å…¥ Milvus
    print("é–‹å§‹æ’å…¥ Milvus...")
    batch_size = 1000
    for i in range(0, len(vector_data), batch_size):
        batch = vector_data[i:i+batch_size]
        collection_text.insert(batch)
    collection_text.flush()

    print(f"âœ… Inserted {len(vector_data)} text embeddings into Milvus.")
    print("ç•¶å‰ entities æ•¸:", collection_text.num_entities)

